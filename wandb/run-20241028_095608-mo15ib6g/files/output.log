/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Epoch: 0, Batch: 0, Loss: 4.1118
Epoch: 0, Batch: 10, Loss: 3.7912
Epoch: 0, Batch: 20, Loss: 3.7300
Epoch: 0, Batch: 30, Loss: 3.8954
Epoch: 0, Batch: 40, Loss: 3.7496
Epoch: 0, Batch: 50, Loss: 3.7018
Epoch: 0, Batch: 60, Loss: 3.4314
Epoch: 0, Batch: 70, Loss: 3.5075
Epoch: 0, Batch: 80, Loss: 3.4086
Epoch: 0, Batch: 90, Loss: 3.4727
Epoch: 0, Batch: 100, Loss: 3.3266
Epoch: 0, Batch: 110, Loss: 3.4959
Epoch: 0, Batch: 120, Loss: 3.1600
Epoch: 0, Batch: 130, Loss: 3.1445
Epoch: 0, Batch: 140, Loss: 3.2237
Epoch: 0, Batch: 150, Loss: 2.9585
Epoch: 0, Batch: 160, Loss: 3.1760
Epoch: 0, Batch: 170, Loss: 2.9492
Epoch: 0, Batch: 180, Loss: 3.0935
Epoch: 0, Batch: 190, Loss: 3.1934
Epoch: 0, Batch: 200, Loss: 2.7888
Epoch: 0, Batch: 210, Loss: 2.6675
Epoch: 0, Batch: 220, Loss: 2.9899
Epoch: 0, Batch: 230, Loss: 2.3902
Epoch: 0, Batch: 240, Loss: 1.9924
Epoch: 0, Batch: 250, Loss: 2.4219
Epoch: 0, Batch: 260, Loss: 2.4826
Epoch: 0, Batch: 270, Loss: 2.5098
Epoch: 0, Batch: 280, Loss: 2.3893
Epoch: 0, Batch: 290, Loss: 2.2511
Validation Loss: 2.1115, Accuracy: 56.0811
Epoch: 1, Batch: 0, Loss: 2.1050
Epoch: 1, Batch: 10, Loss: 1.9102
Epoch: 1, Batch: 20, Loss: 1.8981
Epoch: 1, Batch: 30, Loss: 1.7856
Epoch: 1, Batch: 40, Loss: 1.8990
Epoch: 1, Batch: 50, Loss: 2.0622
Epoch: 1, Batch: 60, Loss: 2.0617
Epoch: 1, Batch: 70, Loss: 1.6993
Epoch: 1, Batch: 80, Loss: 1.7182
Epoch: 1, Batch: 90, Loss: 2.0021
Epoch: 1, Batch: 100, Loss: 1.8782
Epoch: 1, Batch: 110, Loss: 1.6911
Epoch: 1, Batch: 120, Loss: 1.4095
Epoch: 1, Batch: 130, Loss: 1.5107
Epoch: 1, Batch: 140, Loss: 1.4460
Epoch: 1, Batch: 150, Loss: 1.5869
Epoch: 1, Batch: 160, Loss: 1.4707
Epoch: 1, Batch: 170, Loss: 1.3593
Epoch: 1, Batch: 180, Loss: 1.4632
Epoch: 1, Batch: 190, Loss: 1.4611
Epoch: 1, Batch: 200, Loss: 1.9817
Epoch: 1, Batch: 210, Loss: 1.4631
Epoch: 1, Batch: 220, Loss: 1.0976
Epoch: 1, Batch: 230, Loss: 1.5159
Epoch: 1, Batch: 240, Loss: 1.0268
Epoch: 1, Batch: 250, Loss: 1.2790
Epoch: 1, Batch: 260, Loss: 1.3235
Epoch: 1, Batch: 270, Loss: 1.0820
Epoch: 1, Batch: 280, Loss: 0.9302
Epoch: 1, Batch: 290, Loss: 1.2306
Validation Loss: 1.1091, Accuracy: 79.3919
Epoch: 2, Batch: 0, Loss: 0.9437
Epoch: 2, Batch: 10, Loss: 1.3228
Epoch: 2, Batch: 20, Loss: 1.1327
Epoch: 2, Batch: 30, Loss: 1.3841
Epoch: 2, Batch: 40, Loss: 0.8805
Epoch: 2, Batch: 50, Loss: 1.1999
Epoch: 2, Batch: 60, Loss: 0.8430
Epoch: 2, Batch: 70, Loss: 0.8285
Epoch: 2, Batch: 80, Loss: 0.9319
Epoch: 2, Batch: 90, Loss: 0.9976
Epoch: 2, Batch: 100, Loss: 1.3558
Epoch: 2, Batch: 110, Loss: 0.9283
Epoch: 2, Batch: 120, Loss: 0.9871
Epoch: 2, Batch: 130, Loss: 0.8762
Epoch: 2, Batch: 140, Loss: 1.0388
Epoch: 2, Batch: 150, Loss: 0.6464
Epoch: 2, Batch: 160, Loss: 0.8349
Epoch: 2, Batch: 170, Loss: 0.8212
Epoch: 2, Batch: 180, Loss: 0.7152
Epoch: 2, Batch: 190, Loss: 1.0683
Epoch: 2, Batch: 200, Loss: 0.8048
Epoch: 2, Batch: 210, Loss: 0.5674
Epoch: 2, Batch: 220, Loss: 0.6113
Epoch: 2, Batch: 230, Loss: 0.5509
Epoch: 2, Batch: 240, Loss: 0.4983
Epoch: 2, Batch: 250, Loss: 0.5621
Epoch: 2, Batch: 260, Loss: 0.5408
Epoch: 2, Batch: 270, Loss: 0.6831
Epoch: 2, Batch: 280, Loss: 0.7205
Epoch: 2, Batch: 290, Loss: 0.4722
Validation Loss: 0.7570, Accuracy: 85.8108
Epoch: 3, Batch: 0, Loss: 0.5899
Epoch: 3, Batch: 10, Loss: 0.4056
Epoch: 3, Batch: 20, Loss: 0.8017
Epoch: 3, Batch: 30, Loss: 0.5628
Epoch: 3, Batch: 40, Loss: 0.7776
Epoch: 3, Batch: 50, Loss: 0.6638
Epoch: 3, Batch: 60, Loss: 0.4048
Epoch: 3, Batch: 70, Loss: 0.3906
Epoch: 3, Batch: 80, Loss: 0.5970
Epoch: 3, Batch: 90, Loss: 0.5760
Epoch: 3, Batch: 100, Loss: 0.2751
Epoch: 3, Batch: 110, Loss: 0.3941
Epoch: 3, Batch: 120, Loss: 0.3888
Epoch: 3, Batch: 130, Loss: 0.3813
Epoch: 3, Batch: 140, Loss: 0.4926
Epoch: 3, Batch: 150, Loss: 0.8579
Epoch: 3, Batch: 160, Loss: 0.5029
Epoch: 3, Batch: 170, Loss: 0.4610
Epoch: 3, Batch: 180, Loss: 0.4706
Epoch: 3, Batch: 190, Loss: 0.8520
Epoch: 3, Batch: 200, Loss: 0.7378
Epoch: 3, Batch: 210, Loss: 0.6655
Epoch: 3, Batch: 220, Loss: 0.5866
Epoch: 3, Batch: 230, Loss: 0.4906
Epoch: 3, Batch: 240, Loss: 0.3850
Epoch: 3, Batch: 250, Loss: 0.4838
Epoch: 3, Batch: 260, Loss: 0.6298
Epoch: 3, Batch: 270, Loss: 0.4573
Epoch: 3, Batch: 280, Loss: 0.4834
Epoch: 3, Batch: 290, Loss: 0.2649
Validation Loss: 0.5775, Accuracy: 88.1757
Epoch: 4, Batch: 0, Loss: 0.5556
Epoch: 4, Batch: 10, Loss: 0.2747
Epoch: 4, Batch: 20, Loss: 0.2528
Epoch: 4, Batch: 30, Loss: 0.6346
Epoch: 4, Batch: 40, Loss: 0.2965
Epoch: 4, Batch: 50, Loss: 0.2569
Epoch: 4, Batch: 60, Loss: 0.2810
Epoch: 4, Batch: 70, Loss: 0.3502
Epoch: 4, Batch: 80, Loss: 0.4583
Epoch: 4, Batch: 90, Loss: 0.3596
Epoch: 4, Batch: 100, Loss: 0.3018
Epoch: 4, Batch: 110, Loss: 0.4167
Epoch: 4, Batch: 120, Loss: 0.3874
[34m[1mwandb[0m: Ctrl + C detected. Stopping sweep.
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0a7390e1f0>> (for post_run_cell):
Traceback (most recent call last):
  File "<ipython-input-10-91619fb71fda>", line 29, in train_model_sweep
    for i, (images, targets) in enumerate(train_loader):
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataset.py", line 240, in __getitem__
    return self.datasets[dataset_idx][sample_idx]
  File "<ipython-input-2-623b176dce5a>", line 24, in __getitem__
    img = self.transform(img)
  File "/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py", line 135, in __call__
    return F.to_tensor(pic)
  File "/opt/conda/lib/python3.8/site-packages/torchvision/transforms/functional.py", line 169, in to_tensor
    img = img.permute((2, 0, 1)).contiguous()
Exception
